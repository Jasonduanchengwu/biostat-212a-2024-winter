---
title: "Biostat 212a Homework 4"
subtitle: "Due Mar. 5, 2024 @ 11:59PM"
author: "Chengwu Duan and 606332825"
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

## ISL Exercise 8.4.3 (10pts)

Consider the Gini index, classification error, and entropy in a simple
classification setting with two classes. Create a single plot that displays
each of these quantities as a function of \(\hat{p}_{m1}\). The x-axis should
display \(\hat{p}_{m1}\), ranging from 0 to 1, and the y-axis should display the
value of the Gini index, classification error, and entropy.

Hint: In a setting with two classes, \(\hat{p}_{m1}\) = 1âˆ’ \(\hat{p}_{m2}\). You could make
this plot by hand, but it will be much easier to make in R.

**Answer: **

\(\hat{p}_{mk}\) is the proportion of training observations in the \(m^{th}\) region that are from the \(k^{th}\) class. 

The Gini index is defined by

$$
\begin{align}
G &= \sum_{k=1}^{K} \hat{p}_{mk} (1 - \hat{p}_{mk})\\
&= \hat{p}_{m1} (1 - \hat{p}_{m1}) + \hat{p}_{m2} (1 - \hat{p}_{m2})\\
\end{align}
$$
Classification error is defined by

$$
\begin{align}
E &= 1 - \max_k \hat{p}_{mk}\\
&= 1 - \max(\hat{p}_{m1}, \hat{p}_{m2})
\end{align}
$$
Entropy is defined by

$$
\begin{align}
D &= -\sum_{k=1}^{K} \hat{p}_{mk} \log \hat{p}_{mk}\\
&= -\hat{p}_{m1} \log \hat{p}_{m1} - \hat{p}_{m2} \log \hat{p}_{m2}
\end{align}
$$

```{r, message = F, warning=F}
library(tidyverse)
library(ggplot2)

phat.m1 <- seq(0, 1, 0.001)
phat.m2 <- 1 - phat.m1

gini_index <- phat.m1*(1-phat.m1) + phat.m2*(1-phat.m2)
class_error <- 1 - pmax(phat.m1, phat.m2)
entropy <- -phat.m1*log(phat.m1) - phat.m2*log(phat.m2)


data.frame(phat.m1, phat.m2, class_error, gini_index, entropy) %>%
  pivot_longer(cols = c(class_error, gini_index, entropy), names_to = "measures") %>%
    ggplot(aes(x = phat.m1, y = value, col = factor(measures))) + 
    geom_line() + 
    scale_y_continuous(breaks = seq(0, 1, 0.1), minor_breaks = NULL) + 
    scale_color_hue(labels = c("Classification Error", "Entropy", "Gini Index")) +
    labs(title = "Gini Index, Classification Error, and Entropy", 
         subtitle = "as a function of p_hat_m1",
         col = "Measures", 
         y = "Value", 
         x = "Proportion of m1") +
  theme_bw()
```
## ISL Exercise 8.4.4 (10pts)

This question relates to the plots in Figure 8.14.

![](./8.3.png)

(a) Sketch the tree corresponding to the partition of the predictor
space illustrated in the left-hand panel of Figure 8.14. The numbers
inside the boxes indicate the mean of Y within each region.

**Answer: ** 

![](./8.4.4.a.jpg)

(b) Create a diagram similar to the left-hand panel of Figure 8.14,
using the tree illustrated in the right-hand panel of the same
figure. You should divide up the predictor space into the correct
regions, and indicate the mean for each region.

**Answer: ** 

```{r}
library(ggplot2)

# Create an empty plot
ggplot() +
  # set the x and y limits
  xlim(c(-2, 2)) + 
  ylim(c(-3, 3)) +
  # Add rectangles for the regions
  geom_rect(aes(xmin=-2, xmax=2, ymin=2, ymax=3), fill="white", color="black") +
  geom_rect(aes(xmin=0, xmax=2, ymin=1, ymax=2), fill="white", color="black") +
  geom_rect(aes(xmin=-2, xmax=0, ymin=1, ymax=2), fill="white", color="black") +
  geom_rect(aes(xmin=-2, xmax=1, ymin=-3, ymax=1), fill="white", color="black") +
  geom_rect(aes(xmin=1, xmax=2, ymin=-3, ymax=1), fill="white", color="black") +
  # Annotate the regions with the corresponding mean values
  annotate("text", x = 0, y = 2.5, label = "Mean = 2.49", size=4) + 
  annotate("text", x = -1, y = 1.5, label = "Mean = -1.06", size=4) +
  annotate("text", x = 1, y = 1.5, label = "Mean = 0.21", size=4) +
  annotate("text", x = -0.5, y = -1, label = "Mean = -1.80", size=4) +
  annotate("text", x = 1.5, y = -1, label = "Mean = 0.63", size=4) +
  # Add labels and theme adjustments
  labs(x="X1", y="X2", title="Feature Space Divided by Decision Tree") +
  theme_minimal()
```

## ISL Exercise 8.4.5 (10pts)

**Answer: **

## ISL Lab 8.3. `Boston` data set (30pts)

Follow the machine learning workflow to train regression tree, random forest, and boosting methods for predicting `medv`. Evaluate out-of-sample performance on a test set.

**Answer: **

## ISL Lab 8.3 `Carseats` data set (30pts)

Follow the machine learning workflow to train classification tree, random forest, and boosting methods for classifying `Sales <= 8` versus `Sales > 8`. Evaluate out-of-sample performance on a test set.

**Answer: **

