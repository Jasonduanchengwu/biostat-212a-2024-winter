---
title: "Biostat 212a Homework 1"
subtitle: "Due Jan 23, 2024 @ 11:59PM"
author: "Chengwu Duan (Jason) and 606332825"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
editor: 
  markdown: 
    wrap: 72
---

## Filling gaps in lecture notes (10pts)

Consider the regression model $$
Y = f(X) + \epsilon,
$$ where $\operatorname{E}(\epsilon) = 0$.

### Optimal regression function

Show that the choice $$
f_{\text{opt}}(X) = \operatorname{E}(Y | X)
$$ minimizes the mean squared prediction error

$$
\operatorname{E}[(Y - f(X))^2],
$$

where the expectations averages over variations in both $X$ and $Y$.
(Hint: condition on $X$.)

**Answer:** 
$$
\begin{align*}
\operatorname{E}\{[Y - f(X)]^2\} & = \operatorname{E}\{[Y - \operatorname{E}(Y|X)+\operatorname{E}(Y|X)-f(X)]^2\}\\
& =\operatorname{E}\{[(Y - \operatorname{E}(Y|X))+(\operatorname{E}(Y|X)-f(X))]^2\}\\
& =\operatorname{E}\{[Y-E(Y|X)]^2\}+\operatorname{E}\{[E(Y|X)-f(X)]^2\}+\underbrace{2\operatorname{E}\{[E(Y|X)-f(X)][Y-E(Y|X)]\}}_{(3)}\\
(3)&=2\operatorname{E}\{[E(Y|X)-f(X)][Y-E(Y|X)]\}\\
&=2\operatorname{E}\{{\operatorname{E}\{[E(Y|X)-f(X)][Y-E(Y|X)]\}|X}\} \text{(Law of total expectation)}\\
&=2\operatorname{E}\{[E(Y|X)-f(X)]\underbrace{[E(Y|X)-E(Y|X)]}_{=0}\}\\
\operatorname{E}\{[Y - f(X)]^2\} 
& =\operatorname{E}\{[Y-E(Y|X)]^2\}+\operatorname{E}\{\underbrace{[E(Y|X)-f(X)]^2}_{\geq0}\}\\
\operatorname{E}\{[Y - f(X)]^2\}&\geq\underbrace{\operatorname{E}\{[Y-E(Y|X)]^2\}}_{\text{Irreducible}}
\end{align*}
$$ 

\### Bias-variance trade-off

Given an estimate $\hat f$ of $f$, show that the test error at a $x_0$
can be decomposed as $$
\operatorname{E}[y_0 - \hat f(x_0)]^2 = \underbrace{\operatorname{Var}(\hat f(x_0)) + [\operatorname{Bias}(\hat f(x_0))]^2}_{\text{MSE of } \hat f(x_0) \text{ for estimating } f(x_0)} + \underbrace{\operatorname{Var}(\epsilon)}_{\text{irreducible}},
$$ where the expectation averages over the variability in $y_0$ and $\hat f$.

**Answer:** $$
\begin{align*}
\operatorname{E}[y_0 - \hat f(x_0)]^2 & = \operatorname{E}[(y_0 - f(x_0) + f(x_0) - \hat f(x_0)]^2\\
& =\operatorname{E}[(y_0 - f(x_0))^2 + (f(x_0) - \hat f(x_0))^2 + 2(y_0 - f(x_0))(f(x_0) - \hat f(x_0))]\\
& =\operatorname{E}[(y_0 - f(x_0))^2] + \operatorname{E}[(f(x_0) - \hat f(x_0))^2] + 2\operatorname{E}[(y_0 - f(x_0))(f(x_0) - \hat f(x_0))]\\
& =\operatorname{E}[(f(x_0)+\epsilon - f(x_0))^2] + \operatorname{E}[(f(x_0) - \hat f(x_0))^2] + 2\operatorname{E}[(f(x_0)+\epsilon - f(x_0))]\operatorname{E}[(f(x_0) - \hat f(x_0))]\\
& =\operatorname{E}[(\epsilon)^2] + \operatorname{E}[(f(x_0) - \hat f(x_0))^2] + \underbrace{2\operatorname{E}[\epsilon]\operatorname{E}[(f(x_0) - \hat f(x_0))]}_{\operatorname{E}(\epsilon)=0}\\
& =\operatorname{Var}(\epsilon) + \operatorname{E}[(f(x_0) - \hat f(x_0))^2] + 0\\
& =\underbrace{\operatorname{Var}(\hat f(x_0)) + [\operatorname{Bias}(\hat f(x_0))]^2}_{\operatorname{E}[(f(x_0) - \hat f(x_0))^2]} + \underbrace{\operatorname{Var}(\epsilon)}_{\text{irreducible}}
\end{align*}
$$

## ISL Exercise 2.4.3 (10pts)

## ISL Exercise 2.4.4 (10pts)

You will now think of some real-life applications for statistical
learning.

\(a\) Describe three real-life applications in which classification
might be useful. Describe the response, as well as the predictors. Is
the goal of each application inference or prediction? Explain your
answer.

**Answer:**

One such useful application could be detecting phishing emails, then the
user can be protected from phishing scams with email. The response
variable would be the classification of whether said incoming email is
either belonging in the category of "Phish" or "Not Phish". The
predictors could include email address, email content, attachments or
other metadata of said email. The goal of this application is
prediction, the model will predict the probability of said email being
phish given the predictors.

Another useful application could be image recognition in autonomous
vehicles. In autonomous driving, it involves classification with
identifying the object in the camera of the vehicle to make the next
decision. The response variable would be class labels of learned objects
like other cars, trees, wall, pedestrian etc. The predictors could be
pixels RGB values captured by the sensors or cameras. The goal for this
particular purpose is prediction, where the model will predict the
object in the surroundings captured by the sensors to make the next
decision for autonomous driving purposes.

Third application could be diagnosis of diseases, this could report a
specific possible disease given predictors. The response variable would
be the probability of a medical condition and inferred presence of said
condition. The predictors could be the symptoms and the medical history
of the patient etc. The goal of this model would involve both inference
and prediction, where predictions is involved with determining the
probability of a disease and an inference would be made about the
presence of that disease in the patient.

\(b\) Describe three real-life applications in which regression might be
useful. Describe the response, as well as the predictors. Is the goal of
each application inference or prediction? Explain your answer.

**Answer:**

One application could be temperature prediction. The response would be
temperature. The predictors would be variables like wind speed, air
pressure, humidity and geographical locations etc. The goal of this
model would be to predict the temperature given the predictors.

Another possible application could be in research like risk factors of
lung cancer. The response variable would be probability of lung cancer,
while predictors could be the number of cigarette smoked per week, diet,
exercise etc. The goal of this model would be inference using regression
analysis to infer the relationships between different predictors and the
probability of developing the lung cancer.

Another application could be productivity in the workplace. The response
variable would be the productivity level of employees. The predictors
could be job satisfaction, income pay, work hours etc. The goal of the
model would be inference, to infer the relationship different predictors
effects on employee productivity.

\(c\) Describe three real-life applications in which cluster analysis
might be useful.

**Answer:**

One application could be healthcare patient segmentation. Personalized
healthcare interventions can be developed for each patient segment based
on the health indicators, medical history etc. The patient outcome could
be greatly improved with the tailored treatment approach.

Another application could be anomaly detection. The goal of this model could be to identify unusual patterns in the data that do not conform to expected behavior. This could be useful in identifying outliers in data which is crucial in fraud detection, network security and quality control etc.

Third application could be in genomic research where researchers use cluster analysis to group genes or proteins with similar expression patterns. This could be useful in identifying genes or proteins that are co-regulated or co-expressed. This helps in understanding the biological functions of genes and proteins, genetic relations and drug development etc.

## ISL Exercise 2.4.10 (30pts)

Your can read in the `boston` data set directly from url
<https://raw.githubusercontent.com/ucla-biostat-212a/2024winter/master/slides/data/Boston.csv>.
A documentation of the `boston` data set is
[here](https://www.rdocumentation.org/packages/ISLR2/versions/1.3-2/topics/Boston).

#### R

```{r, evalue = T}
library(tidyverse)
Boston <- read_csv("https://raw.githubusercontent.com/ucla-biostat-212a/2024winter/master/slides/data/Boston.csv", col_select = -1) %>% 
  print(width = Inf)
```
\(a\)How many rows are in this data set? How many columns? What do the rows and columns represent?

**Answer: ** There are 506 rows and 14 columns in the data set. The rows represent the different suburbs in the Boston area and the columns represent the different attributes of the suburbs.

\(b\)
Make some pairwise scatterplots of the predictors (columns) in
this data set. Describe your findings.

```{r, evalue = T}
library(tidyverse)
library(GGally)
Bostonpairs=ggpairs(data=Boston, lower = list(continuous = wrap("points", alpha = 0.3, size=0.2)), diag=list(continuous='barDiag'))
Bostonpairs
```

**Answer: ** There is a strong positive correlation between the number of rooms (`rm`) and the median value of owner-occupied homes (`medv`), with a correlation coefficient of 0.695.This suggests that as the number of rooms (a larger house) tend to be more valuable which is intuitive. The accessibility to radical highways (`rad`) is also highly positively correlated with the index of accessibility to radial highways (`tax`), with a correlation coefficient of 0.910. This suggests that the suburbs with more accessibility to radial highways tend to have higher tax rates.

There is a strong negative correlation between the percentage of lower status of the population (`lstat`) and the median value of owner-occupied homes (`medv`). This suggests that the suburbs with a higher percentage of lower status of the population tend to have lower median value of owner-occupied homes. There is a strong negative correlation between the pupil-teacher ratio by town (`ptratio`) and the median value of owner-occupied homes (`medv`). This suggests that the suburbs with a higher pupil-teacher ratio tend to have lower median value of owner-occupied homes. 

The `chas` variable is a binary variable with 1 indicating that the suburb is bound by the Charles River and 0 otherwise. The `chas` variable is not highly correlated with any other variables, which is expected since it is a binary variable representing a categorical variable.

The histograms along the diagonal show the distribution of each variable. For instance, `crim` (per capita crime rate by town) and `zn` (proportion of residential land zoned for lots over 25,000 sq.ft.) are right-skewed, indicating that most towns have low crime rates and are not predominantly zoned for large residential lots.

Several variables display potential outliers. For example, `crim` has some towns with very high crime rates compared to the majority, and `tax` shows some towns with unusually high tax rates.

\(c\)Are any of the predictors associated with per capita crime rate?
If so, explain the relationship.

**Answer: ** `crim` is positively associated with `rad`, `tax`, `ptratio`, and `lstat`. This suggests that the suburbs with more accessibility to radial highways, higher tax rates, higher pupil-teacher ratio, and higher percentage of lower status of the population tend to have higher crime rates.

`crim` is negatively associated with `zn`, `indus`, `nox`, `rm`, `age`, and `dis`. This suggests that the suburbs with more residential land zoned for lots over 25,000 sq.ft., more non-retail business acres per town, higher nitrogen oxides concentration, more average number of rooms per dwelling, more owner-occupied units built prior to 1940, and longer distances to five Boston employment centres tend to have lower crime rates.

\(d\) Do any of the census tracts of Boston appear to have particularly high crime rates? Tax rates? Pupil-teacher ratios? Comment on the range of each predictor.

**Answer: ** The density distribution of `crim` is positively skewed with the tail in the positive direction, which indicates that the majority of the data points are clustered in the lower end of the scale infering that crime rates are typically low. However we can see few census tracts dotted on the higher end, indicating that there is census tracts with higher crime rate. Thus in general, crime rates are usually low but there are some areas with particularly high crime rates. The super high peaks indicates high variability, but since range represents the presence of extreme values and not the density of those values, `crim` predictor has a large range since there are presence of both extreme values.

The density distribution of `tax` looked normal at large on the lower end of the plot, where there is an increasing occurances as higher taxes to a certain point and taxes occurances dropped further after that point as taxes increases. However there is a high occurance of high taxes on the right end. The two peaks suggests that there are common tax rates that many tracts share with low or high tax rates, and the gap between these peaks indicate fewer tracts with intermediate tax rates. As a whole, I would say that the distribution of `tax` is multimodal, thus there could be distinct subgroups within the `tax` data. Since the start point and end point of the histogram is far apart, I am inclined to say that the range of `tax` is large but with variability.

The distribution of `ptratio` is relatively uniform compared to `crime` or `tax`, but there are still a high density of census tracks with notably high pupil-teacher ratios, which can be inferred from the data points towards the upper end of the histogram. Based on the visual representation of the histogram, the range of `ptratio` is pretty large as the width of the distribution is long and the data is spread out and evenly distributed. Just by looking at the scatter plot, `ptratio` predictor would have a large range since there are presence of both extreme values.

\(e\) How many of the census tracts in this data set bound the Charles
river?

**Answer: ** Based on the scatter plot, there are far fewer census tracts that bound thhe charles river than those that do not. We can get the exact amount with the following code.

```{r, evalue = T}
# since chas is a binary variable, we can sum the number of 1s to get the number of census tracts that bound the Charles river
sum(Boston$chas) 

```

There are 35 census tracts that bound the Charles river.

\(f\) What is the median pupil-teacher ratio among the towns in this
data set?

**Answer: ** We can get the median pupil-teacher ratio among the towns in this data set with the following code.

```{r, evalue = T}
median(Boston$ptratio)
```
The median pupil-teacher ratio among the towns in this data set is 19.05.

\(g\) Which census tract of Boston has lowest median value of owner-occupied
homes? What are the values of the other predictors
for that census tract, and how do those values compare to the
overall ranges for those predictors? Comment on your findings.

**Answer: ** We can get the census tract of Boston with the lowest median value of owner-occupied homes with the following code. The other values are also displayed .

```{r, evalue = T}
library(ggplot2)
library(reshape2)
library(dplyr)

# Identify the tract with the lowest median home value
min_medv_row = Boston[which.min(Boston$medv), ]
print(min_medv_row)

# Tax has a larger range than the other predictors, so we will exclude it from the boxplots to show on a separate plot so that we can see the other predictors more clearly.

# Convert the Boston dataset to a long format excluding `tax`
long_boston_without_tax = Boston %>% 
  select(-tax) %>% 
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Convert the specific tract values to a long format excluding `tax`
specific_tract_without_tax = min_medv_row %>% 
  select(-tax) %>% 
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Plot for all predictors except `tax`
ggplot(long_boston_without_tax, aes(x = Predictor, y = Value)) +
  geom_boxplot() +
  geom_point(data = specific_tract_without_tax, aes(x = Predictor, y = Value), color = "red") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Box Plot of Boston Dataset Predictors without Tax")

# Convert the `tax` data to long format
long_boston_tax = Boston %>% 
  select(tax) %>% 
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Convert the specific tract `tax` value to long format
specific_tract_tax = min_medv_row %>% 
  select(tax) %>% 
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Plot only for `tax`
ggplot(long_boston_tax, aes(x = Predictor, y = Value)) +
  geom_boxplot() +
  geom_point(data = specific_tract_tax, aes(x = Predictor, y = Value), color = "red") +
  labs(title = "Box Plot of Boston Dataset Tax Predictor")

```
The `age` in the specific tract is at the top of the whiskers which indicates that it has older (could be oldest) buildings compared to the other tracts. 

Since `chas` a binary variable, the box plot isn't particularly informative. The specific tract does not border the Charles River. 

The specific tract has high `crim` which would be considered an outlier. 

The `dis` value lies lower than the median and close to the lower quartile suggesting that it is closer to employment center than other tracts. 

The `indus` value is close to the third quartile which suggest that the tract has a high proportion of non-retail business acres per town than many other tracts. 

The value for `lstat` is very high in this tract, way above the third quartile which suggests that there is a higher percentage of lower status of the population in this tract. 

As we know that this tract is the lowest `medv` in Boston. 

The `nox` values seems to be above the median which indicates a higher nitrogen oxides concentration in this tract. 

The pupil-teacher ratio (`ptratio`) is at the upper quartile but within the interquartile range, indicating a higher than average ratio. 

Accessibility to radial highways (`rad`) is at the third quartile for this tract, indicates that it has higher accessibility to radial highways than other tracts. 

The average number of rooms per dwelling (`rm`) is below the median, suggesting smaller dwelling sizes in this tract. 

The proportion of residential land zoned for lots over 25,000 (`zn`) square feet is at the median, which is common in the dataset.

`tax` is at the upper quartile, indicating that this tract has a higher tax rate than other tracts.

\(h\) In this data set, how many of the census tracts average more than
seven rooms per dwelling? More than eight rooms per dwelling?
Comment on the census tracts that average more than eight
rooms per dwelling.

**Answer: **

```{r,eval=T}
library(ggplot2)
library(dplyr)
# Number of census tracts that average more than seven rooms per dwelling
sum(Boston$rm > 7)

# more than 8
sum(Boston$rm > 8)

# Comment on the census tracts that average more than eight rooms per dwelling
boston_morethan_8 = Boston[Boston$rm > 8, ]
boston_morethan_8

# to comment on the 13 census tracts, I would like to take the median value to represent all of them
average = apply(boston_morethan_8, 2, median)
average = as.data.frame(t(average))
print(average)

# Convert the Boston dataset to a long format excluding `tax`
long_boston_without_tax = Boston %>%
  select(-tax) %>%
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Convert the specific tract values to a long format excluding `tax`
average_without_tax = average %>%
  select(-tax) %>%
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Plot for all predictors except `tax`
ggplot(long_boston_without_tax, aes(x = Predictor, y = Value)) +
  geom_boxplot() +
  geom_point(data = average_without_tax, aes(x = Predictor, y = Value), color = "red") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Box Plot of Boston Dataset Predictors without Tax")

# Convert the `tax` data to long format
long_boston_tax = Boston %>%
  select(tax) %>%
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Convert the specific tract `tax` value to long format
average_tax = average %>%
  select(tax) %>%
  pivot_longer(cols = everything(), names_to = "Predictor", values_to = "Value")

# Plot only for `tax`
ggplot(long_boston_tax, aes(x = Predictor, y = Value)) +
  geom_boxplot() +
  geom_point(data = average_tax, aes(x = Predictor, y = Value), color = "red") +
  labs(title = "Box Plot of Boston Dataset Tax Predictor")
```
Notably there are only 13 census tracts that average more than eight rooms per dwelling.


## ISL Exercise 3.7.3 (12pts)

## ISL Exercise 3.7.15 (20pts)

## Bonus question (20pts)

For multiple linear regression, show that $R^2$ is equal to the
correlation between the response vector
$\mathbf{y} = (y_1, \ldots, y_n)^T$ and the fitted values
$\hat{\mathbf{y}} = (\hat y_1, \ldots, \hat y_n)^T$. That is $$
R^2 = 1 - \frac{\text{RSS}}{\text{TSS}} = [\operatorname{Cor}(\mathbf{y}, \hat{\mathbf{y}})]^2.
$$
